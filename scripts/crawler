#!/usr/bin/env ruby

require 'rubygems'
require 'httpclient'
require 'json'

class Crawl
  
  def initialize(http, links, url, base)
    @http = http
    @links = links
    @url = url.gsub(/&amp;/, '&')
    @base = base
  end
  
  def crawl()
    return if /^mailto/.match(@url) || /github\.com/.match(@url)
    url = @url.match(/http(s)?:\/\//) ? @url : "#{@base}#{@url}"
    return if @links.has_key?(url)
    
    if /^#{@base}/.match(url)
      page = @http.get(url)
      @links[url] = page.status.to_s.to_i

      if page.headers['Content-Type'] =~ /^text\//
        page.body.scan(/href="(.*?)"/i).flatten.each do |link|
          Crawl.new(@http, @links, link, @base).crawl
        end
      end
    else
      begin
        page = @http.get(url)
        @links[url] = page.status.to_s.to_i
      rescue
        @links[url] = -1
      end
    end
    puts "#{@links[url]}: #{url}"
  end
end

links = {}

http = HTTPClient.new
http.ssl_config.verify_mode = OpenSSL::SSL::VERIFY_NONE

Crawl.new(http, links, 'http://localhost:8080', 'http://localhost:8080').crawl
open('crawl.json', 'w') {|f| f.write links.to_json }
