#!/usr/bin/env ruby

require 'rubygems'
require 'httpclient'
require 'json'

class Crawl
  
  def initialize(http, links, url, base)
    @http = http
    @links = links
    @url = url.gsub(/&amp;/, '&')
    @base = base
  end
  
  def crawl()
    return if /^mailto/.match(@url)
    url = @url.match(/http(s)?:\/\//) ? @url : "#{@base}#{@url}"
    return if @links.has_key?(url)
    
    if /^#{@base}/.match(url)
      page = @http.get(url)
      @links[url] = case page.status.to_s.to_i
      when (0..299)
        :ok
      when (300..399)
        :redirect
      when (400..499)
        :client_error
      when (500..599)
        :server_error
      end
      page.body.scan(/href="(.*?)"/i).flatten.each do |link|
        Crawl.new(@http, @links, link, @base).crawl
      end
    else
      @links[url] = :external
    end
  end
end

links = {}
Crawl.new(HTTPClient.new, links, 'http://localhost:8080', 'http://localhost:8080').crawl
puts links.to_json