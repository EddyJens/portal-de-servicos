#!/usr/bin/env ruby

require 'rubygems'
require 'httpclient'

@http = HTTPClient.new
$base_url = 'http://localhost:8081/'

$all_links = Array.new
$accessed_links = Array.new
$skipped_links = Array.new

def main()
	# Access URL
	url_access_level1 = accessUrl($base_url, 0)
	
	# Get all hrefs from a page
	link_level1 = getHrefs(url_access_level1)
	
	# Check each link/href
	link_level1.uniq.each_with_index do |link1, index|
	
		# Fix the URL format
		url_level1 = fixingUrl(link1)
		
		# Check URL and add in a list
		addList(url_level1, 1)
		
		# Access the URL from Level 1
		if not $accessed_links.include? url_level1 and not url_level1.include? "feedback" and url_level1.include? $base_url
			url_access_level2 = accessUrl(url_level1, 1)
			link_level2 = getHrefs(url_access_level2)
			link_level2.uniq.each_with_index do |link2, index|
				url_level2 = fixingUrl(link2)
				addList(url_level2, 2)
				
				# Access the URL from Level 2
				if not $accessed_links.include? url_level2 and not url_level2.include? "feedback" and url_level2.include? $base_url
					url_access_level3 = accessUrl(url_level2, 2)
					link_level3 = getHrefs(url_access_level3)
					link_level3.uniq.each_with_index do |link3, index|
						url_level3 = fixingUrl(link3)
						addList(url_level3, 3)
						
						# Access the URL from Level 3
						if not $accessed_links.include? url_level3 and not url_level3.include? "feedback" and url_level3.include? $base_url
							url_access_level3 = accessUrl(url_level3, 3)
							link_level4 = getHrefs(url_access_level3)
							link_level4.uniq.each_with_index do |link4, index|
								url_level4 = fixingUrl(link4)
								addList(url_level4, 4)
							end
						end
					end			
				end
			end
		end	
	end
	
	puts "   ########### END OF MAPPING!!!! ###########   "
	
	# ACCESSED LINKS
	generateReport("accessed_links_from5", $accessed_links, false)

	# SKIPPED LINKS
	generateReport("skipped_links_from5", $skipped_links, false)
	
	# ALL LINKS WITH STATUS
	generateReport("all_links_from5", $all_links, true)
end

def getHrefs(page)
	href = page.body.scan(/href="(.*?)"/i)
end

def accessUrl(url, level)
	url_access = @http.get url
	$accessed_links << url
	puts "ADDED IN ACCESSED LINKS - LEVEL #{level} : " + url
	return url_access
end

def fixingUrl(url)
	if url.to_s[0..5].include? "www" or url.to_s[0..5].include? "http"
		fixedUrl = url.to_s[2..-3]
	else
		fixedUrl = $base_url.to_s[0..-2] + url.to_s[2..-3]
	end
	return fixedUrl
end

def addList(url, level)
	if not $accessed_links.include? url and not url.include? "feedback" and not $all_links.include? url
		$all_links << url
		puts "ADDED IN ALL LINKS - LEVEL 1 : " + url
	else
		puts " ############### HAS FEEDBACK or ALREADY ACCESSED => " + url
		if url.include? "feedback"
			$skipped_links << url
			puts "ADDED IN SKIPPED LINKS - LEVEL #{level} : " + url
		end
	end
end

def generateReport(name, list, access)
	generateReport = File.new("#{name}.html", "w+")
	generateReport.puts "<HTML><BODY>"
	generateReport.puts "<TABLE BORDER='1'>"
	if access == true
		generateReport.puts "<TR><TH>Index</TH><TH>Links</TH><TH>Status</TH></TR>"
	else
		generateReport.puts "<TR><TH>Index</TH><TH>Links</TH></TR>"
	end
	list.uniq.sort.each_with_index do |link, index|
		if access == true
			if not link.include? "www" and not link.include? "feedback" and not link.include? "http://mpa.gov.br" and not link.include? "aviacaocivil" and not link.include? "receita.fazenda"
				begin
				    puts " Accessing the url: " + link.to_s
					url_access = @http.get link
					url_status = url_access.status
					puts "    Status: " + url_status.to_s
			    rescue Exception => url_status 
			    next
			    end
			else
				url_status = "External Link"
				puts " External link: " + link.to_s
			end
		end
		generateReport.puts "<TR>"
		if access == true
			generateReport.puts "<TD>#{index}</TD><TD><a href=\"#{link}\">#{link}</a></TD><TD>#{url_status}</TD>"
		else
			generateReport.puts "<TD>#{index}</TD><TD><a href=\"#{link}\">#{link}</a></TD>"
		end
		generateReport.puts "</TR>"
	end
	generateReport.close()
end

main
